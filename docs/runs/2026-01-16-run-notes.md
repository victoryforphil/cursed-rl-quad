Run notes (2026-01-16)

Runs
- models/run_20260116_223915/
- models/run_20260116_223717/
- models/experiments.csv

Related notes
- docs/runs/2026-01-17-run-notes.md

Snapshot (run_20260116_223915)
- Timesteps: 2,293,760
- Mean reward (last 100): 189.23
- Best reward: 321.26
- Mean waypoints reached: 1.37
- Success rate: 0.0
- Crash rate: 1.0 (excessive_tilt dominant)
- Max tilt: ~80-84 deg in sampled episodes
- Mean speed late episodes: ~6-7 m/s
- Mean episode reward trending up from ~-11 to ~200+ by update ~150

Observations
- Reward rises steadily while crashes stay at 100% due to excessive tilt.
- Later episodes show 2-3 waypoints reached but still terminate on tilt.
- Training losses/metrics not yet populated in updates.csv (nulls).

Ideas for next improvements (early-signal focus)
- Stability shaping in stage 0 only: increase tilt penalty and add angular-velocity penalty.
- Reduce action scale early to limit aggressive control and tilt.
- Gate curriculum progression on crash_rate or tilt_rate thresholds.
- Add deterministic eval slice (noise=0) every N updates to separate stability from randomness.
- Persist VecNormalize stats across stages to avoid destabilization at transitions.

Test plan (keep changes small per test)
Stage 1 (single-change checks)
- T1: Increase tilt penalty only (stage 0).
- T2: Add angular-velocity penalty only (stage 0).
- T3: Reduce action scale only (stage 0).

Stage 2 (light combinations)
- T4: Tilt penalty + angular-velocity penalty.
- T5: Tilt penalty + reduced action scale.

Stage 3 (curriculum/eval plumbing)
- T6: Gate stage progression on crash_rate or tilt_rate.
- T7: Deterministic eval slice (noise=0) every N updates.
- T8: Persist VecNormalize across stages.

Test prep (current plan)
- Apply T3 first by setting stage_0_hover.action_scale=0.6 and keep other params unchanged.
- Increase training.total_timesteps to 25,000,000 for long runs; keep short test runs smaller.
