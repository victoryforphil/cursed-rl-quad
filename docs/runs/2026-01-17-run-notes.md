Run notes (2026-01-17)

Runs
- models/run_20260116_232936/
- models/experiments.csv

Related notes
- docs/runs/2026-01-16-run-notes.md

Pre-run prep (next run)
- Config source: cfg_default.yaml
- Key changes: action_scale 0.8, tilt_penalty 12.0, include_position false, curriculum enabled

Config snapshot (cfg_default.yaml)
```yaml
training:
  total_timesteps: 15000000
  n_envs: 10
ppo:
  learning_rate: 0.0005
  batch_size: 256
  n_steps: 2048
  n_epochs: 10
env:
  action_scale: 0.8
  include_position: false
  max_tilt_angle: 1.4
reward:
  progress_multiplier: 5.0
  tilt_penalty: 12.0
```

Snapshot (run_20260116_232936)
- Timesteps: 19,763,200
- Mean reward (last 100): 302.13
- Best reward: 642.70
- Mean waypoints reached: 2.80
- Success rate: 0.0
- Crash rate: 1.0 (excessive_tilt dominant)
- Max tilt: ~80-85 deg in sampled episodes
- Mean speed late episodes: ~7-8 m/s
- Mean episode reward stable around ~300-340 near end

Observations
- Reward improved substantially, but success rate remains at 0% with tilt failures.
- Late episodes regularly reach 3-6 waypoints before termination from excessive tilt.
- Training losses/metrics remain null in updates.csv.

Ideas for next improvements (stability focus)
- Reduce action scale to curb aggressive tilt (try 0.7-0.8).
- Increase tilt penalty to bias safer attitudes (try 12.0).
- Enable include_position for better stabilization cues.
- Slightly reduce progress multiplier to avoid reckless pushes (try 3.5-4.0).

Test plan (keep changes small per test)
Stage 1 (single-change checks)
- T1: Reduce action scale only.
- T2: Increase tilt penalty only.
- T3: Enable include_position only.

Stage 2 (light combinations)
- T4: Action scale + tilt penalty.
- T5: Action scale + include_position.

Stage 3 (optional follow-ups)
- T6: Reduce progress multiplier.
- T7: Tighten max tilt angle to 1.1-1.2 rad for early safety.
